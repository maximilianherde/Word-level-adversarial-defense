{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "colab": {
      "name": "BiRLM.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "fb1e2e07"
      },
      "source": [
        "import torch\n",
        "from torchtext.datasets import IMDB, AG_NEWS, YahooAnswers\n",
        "from torchtext.vocab import GloVe\n",
        "from torchtext.data import to_map_style_dataset\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torch.nn import LSTM, GRU, Linear, Softmax, CrossEntropyLoss\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import DataLoader, random_split, Dataset\n",
        "from torch.optim import Adam\n",
        "from tqdm import tqdm"
      ],
      "id": "fb1e2e07",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ad904ad2"
      },
      "source": [
        "DATASET = 'AG_NEWS'\n",
        "MODEL = 'LSTM'\n",
        "VALIDATION_SPLIT = 0.5 # of test data\n",
        "BATCH_SIZE = 64\n",
        "SHUFFLE = True\n",
        "NUM_EPOCHS = 10\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "id": "ad904ad2",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nd1STifJoCO3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed355df9-8c05-44c2-f47d-ee1b95117420"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "PATH = '/content/drive/MyDrive/Checkpoints/model'\n",
        "!mkdir '/content/drive/MyDrive/Checkpoints/model'"
      ],
      "id": "nd1STifJoCO3",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "mkdir: cannot create directory ‘/content/drive/MyDrive/Checkpoints/model’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1d344f05"
      },
      "source": [
        "class BidirectionalLSTMClassifier(torch.nn.Module):\n",
        "    def __init__(self, num_classes, hidden_size, num_layers):\n",
        "        super().__init__()\n",
        "        self.num_layers = num_layers\n",
        "        self.LSTM = LSTM(50, hidden_size, num_layers=num_layers, batch_first=True, bidirectional=True)\n",
        "        self.linear = Linear(2 * hidden_size, num_classes)\n",
        "        self.softmax = Softmax(dim=1)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        _, (h_n, _) = self.LSTM(x)\n",
        "        h_forward = h_n[2 * self.num_layers - 2]\n",
        "        h_backward = h_n[2 * self.num_layers - 1]\n",
        "        y = self.linear(torch.cat((h_forward, h_backward), 1))\n",
        "        return self.softmax(y)\n",
        "    \n",
        "    \n",
        "class BidirectionalGRUClassifier(torch.nn.Module):\n",
        "    def __init__(self, num_classes, hidden_size, num_layers):\n",
        "        super().__init__()\n",
        "        self.num_layers = num_layers\n",
        "        self.GRU = GRU(50, hidden_size, num_layers=num_layers, batch_first=True, bidirectional=True)\n",
        "        self.linear = Linear(2 * hidden_size, num_classes)\n",
        "        self.softmax = Softmax(dim=1)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        _, h_n = self.GRU(x)\n",
        "        h_forward = h_n[2 * self.num_layers - 2]\n",
        "        h_backward = h_n[2 * self.num_layers - 1]\n",
        "        y = self.linear(torch.cat((h_forward, h_backward), 1))\n",
        "        return self.softmax(y)"
      ],
      "id": "1d344f05",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3dkNIsx4rBhp"
      },
      "source": [
        "class ClassificationDataset(Dataset):\n",
        "    def __init__(self, dataset, num_classes, tokenizer):\n",
        "        self.num_classes = num_classes\n",
        "        self.dataset = dataset\n",
        "        self.tokenizer = tokenizer\n",
        "    \n",
        "    def __len__(self):\n",
        "        return self.dataset.__len__()\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        label, text = self.dataset.__getitem__(idx)\n",
        "        return int(label) - 1, self.tokenizer(text)"
      ],
      "id": "3dkNIsx4rBhp",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d001818b"
      },
      "source": [
        "if DATASET == 'IMDB':\n",
        "    train_set = IMDB(split='train')\n",
        "    test_set = IMDB(split='test')\n",
        "    num_classes = 2\n",
        "elif DATASET == 'AG_NEWS':\n",
        "    train_set = AG_NEWS(split='train')\n",
        "    test_set = AG_NEWS(split='test')\n",
        "    num_classes = 4\n",
        "elif DATASET == 'YahooAnswers':\n",
        "    train_set = YahooAnswers(split='train')\n",
        "    test_set = YahooAnswers(split='test')\n",
        "    num_classes = 10\n",
        "else:\n",
        "    raise ValueError()\n",
        "\n",
        "tokenizer = get_tokenizer('basic_english')\n",
        "embedding = GloVe(name='6B', dim=50)\n",
        "\n",
        "train_set = to_map_style_dataset(train_set)\n",
        "test_set = to_map_style_dataset(test_set)\n",
        "\n",
        "train_set = ClassificationDataset(train_set, num_classes, tokenizer)\n",
        "test_set = ClassificationDataset(test_set, num_classes, tokenizer)\n",
        "test_set, val_set = random_split(test_set, [test_set.__len__() - int(VALIDATION_SPLIT * test_set.__len__()), int(VALIDATION_SPLIT * test_set.__len__())], generator=torch.Generator().manual_seed(42))"
      ],
      "id": "d001818b",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4668a7f"
      },
      "source": [
        "def collate_batch(batch):\n",
        "    label_list, text_list = [], []\n",
        "    for (_label, _tokens) in batch:\n",
        "        label_list.append(_label)\n",
        "        embed = embedding.get_vecs_by_tokens(_tokens)\n",
        "        text_list.append(embed)\n",
        "    label_list = torch.tensor(label_list, dtype=torch.int64)\n",
        "    text_list = pad_sequence(text_list, batch_first=True)\n",
        "    return label_list.to(device), text_list.to(device)\n",
        "\n",
        "train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, collate_fn=collate_batch, shuffle=SHUFFLE)\n",
        "test_loader = DataLoader(test_set, batch_size=BATCH_SIZE, collate_fn=collate_batch, shuffle=SHUFFLE)\n",
        "val_loader = DataLoader(val_set, batch_size=BATCH_SIZE, collate_fn=collate_batch, shuffle=SHUFFLE)"
      ],
      "id": "b4668a7f",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eb76a3bd"
      },
      "source": [
        "def evaluate(model, data_loader, loss=CrossEntropyLoss()):\n",
        "    model.eval()\n",
        "    total_acc, total_count = 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for idx, (labels, text) in enumerate(data_loader):\n",
        "            predicted_label = model(text)\n",
        "            loss_ = loss(predicted_label, labels)\n",
        "            total_acc += (predicted_label.argmax(1) == labels).sum().item()\n",
        "            total_count += labels.size(0)\n",
        "    return total_acc / total_count\n",
        "\n",
        "\n",
        "def train(model, optimizer, train_loader, loss=CrossEntropyLoss(), log_interval=50):\n",
        "    model.train()\n",
        "    total_acc, total_count = 0, 0\n",
        "    pbar = tqdm(total=len(train_loader), desc=f'Epoch [{epoch + 1}/{NUM_EPOCHS}]')\n",
        "    for idx, (labels, text) in enumerate(train_loader):\n",
        "        output = model(text)\n",
        "        loss_ = loss(output, labels)\n",
        "        optimizer.zero_grad()\n",
        "        loss_.backward()\n",
        "        optimizer.step()\n",
        "        total_acc += (output.argmax(1) == labels).sum().item()\n",
        "        total_count += labels.size(0)\n",
        "        pbar.update()\n",
        "        if idx % log_interval == 0 and idx > 0:\n",
        "            pbar.set_postfix(loss=loss_, accuracy=total_acc / total_count)\n",
        "            total_acc, total_count = 0, 0\n",
        "    \n",
        "    pbar.close()"
      ],
      "id": "eb76a3bd",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e05c2e42",
        "outputId": "67af6951-d49e-47c8-b158-e04b5af7f708"
      },
      "source": [
        "model = BidirectionalGRUClassifier(num_classes, 64, 1).to(device)\n",
        "optim = Adam(model.parameters())\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    train(model, optim, train_loader)\n",
        "    val_accuracy = evaluate(model, val_loader)\n",
        "\n",
        "    torch.save({\n",
        "        'epoch' : epoch,\n",
        "        'model_state_dict' : model.state_dict(),\n",
        "        'optimizer_state_dict': optim.state_dict(),\n",
        "        'val_accuracy' : val_accuracy\n",
        "    }, PATH + '_' + str(epoch) + '.pt' )\n",
        "\n",
        "    #How to load a model\n",
        "    #checkpoint = torch.load(PATH)\n",
        "    #model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    #optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "    #epoch = checkpoint['epoch']\n",
        "    #val_accuracy = checkpoint['val_accuracy']"
      ],
      "id": "e05c2e42",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [0/10]: 100%|██████████| 1875/1875 [01:09<00:00, 27.15it/s, accuracy=0.906]\n",
            "Epoch [1/10]: 100%|██████████| 1875/1875 [01:09<00:00, 27.14it/s, accuracy=0.893]\n",
            "Epoch [2/10]: 100%|██████████| 1875/1875 [01:09<00:00, 27.06it/s, accuracy=0.91]\n",
            "Epoch [3/10]: 100%|██████████| 1875/1875 [01:09<00:00, 27.04it/s, accuracy=0.911]\n",
            "Epoch [4/10]: 100%|██████████| 1875/1875 [01:09<00:00, 27.12it/s, accuracy=0.918]\n",
            "Epoch [5/10]: 100%|██████████| 1875/1875 [01:09<00:00, 27.10it/s, accuracy=0.911]\n",
            "Epoch [6/10]: 100%|██████████| 1875/1875 [01:09<00:00, 26.96it/s, accuracy=0.917]\n",
            "Epoch [7/10]: 100%|██████████| 1875/1875 [01:08<00:00, 27.23it/s, accuracy=0.919]\n",
            "Epoch [8/10]: 100%|██████████| 1875/1875 [01:09<00:00, 27.14it/s, accuracy=0.93]\n",
            "Epoch [9/10]: 100%|██████████| 1875/1875 [01:08<00:00, 27.18it/s, accuracy=0.927]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QUlrEqCIFLuJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "403bfb48-3e72-46eb-a647-3cfd535200e6"
      },
      "source": [
        "test_accuracy = evaluate(model, test_loader)\n",
        "print(f'Test accuracy: {test_accuracy}')"
      ],
      "id": "QUlrEqCIFLuJ",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 0.9142105263157895\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5G30ec1aTgv"
      },
      "source": [
        ""
      ],
      "id": "f5G30ec1aTgv",
      "execution_count": null,
      "outputs": []
    }
  ]
}
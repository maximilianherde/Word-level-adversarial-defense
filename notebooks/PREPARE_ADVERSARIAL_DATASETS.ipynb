{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PREPARE_ADVERSARIAL_DATASETS.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# MOUNT G_DRIVE\n",
        "from pathlib import Path\n",
        "from IPython import get_ipython\n",
        "on_colab = 'google.colab' in str(get_ipython())\n",
        "\n",
        "if on_colab:\n",
        "  from google.colab import drive\n",
        "  drive.mount(\"/content/gdrive\")\n",
        "\n",
        "PATH =  \"/content/gdrive/My Drive/DeepLearning/MODELS/\" if on_colab else \"./\"\n",
        "PATH_DATASET = \"/content/gdrive/My Drive/DeepLearning/DATASETS/\" if on_colab else \"./\"\n",
        "\n",
        "# READ DATASETS\n",
        "import pandas as pd\n",
        "from torch.utils.data import Dataset\n",
        "import numpy as np\n",
        "\n",
        "# FILE THAT CONTAINS ADVERSARIAL ATTACK RESULTS\n",
        "FILE_NAME = \"LSTM_YahooAnswers_ADV_EXAMPLES.csv\" #\"LSTM_AG_NEWS_ADV_EXAMPLES_5k.csv\" #\"CNN_IMDB_ADV_EXAMPLES.csv\"\n",
        "\n",
        "# FILE THAT CONTAINS THE ORIGINAL TRAINING SET\n",
        "DIR_TRAIN = 'YahooAnswers' #\"IMDB\" #\"AG_NEWS\"\n",
        "ORIG_TRAIN_NAME = \"/train.csv\"\n",
        "\n",
        "# READ CSVS\n",
        "df = pd.read_csv(PATH_DATASET+FILE_NAME)\n",
        "if DIR_TRAIN == \"AG_NEWS\":\n",
        "    df_orig = pd.read_csv(PATH_DATASET+DIR_TRAIN+ORIG_TRAIN_NAME, header=None)\n",
        "\n",
        "elif DIR_TRAIN == \"IMDB\":\n",
        "    df_orig = pd.read_csv(PATH_DATASET+DIR_TRAIN+ORIG_TRAIN_NAME)\n",
        "\n",
        "elif DIR_TRAIN == \"YahooAnswers\":\n",
        "    df_orig = pd.read_csv(PATH_DATASET+DIR_TRAIN+ORIG_TRAIN_NAME, header=None)\n",
        "\n",
        "\n",
        "# GET LABEL AND ADVERSARIAL EXAMPLE (Successful ones)\n",
        "df_modified = df[df[\"result_type\"] == \"Successful\"][[\"perturbed_text\", \"ground_truth_output\"]].reset_index(drop=True)\n",
        "\n",
        "# CONVERT TO INTEGER\n",
        "df_modified['ground_truth_output'] = df_modified['ground_truth_output'].apply(np.int64)\n",
        "\n",
        "# CHANGE COLUMN NAMES OF ADVERSARIAL SAMPLES\n",
        "df_modified = df_modified.rename(columns={\"perturbed_text\":\"txt\", \"ground_truth_output\":\"label\"})\n",
        "\n",
        "# AG_NEWS HAS 2 COLUMNS CONTAINING TEXT MERGE THEM\n",
        "if DIR_TRAIN == \"AG_NEWS\":\n",
        "    df_orig[\"txt\"] = df_orig[1] + \" \" + df_orig[2]\n",
        "    df_orig_modified = df_orig[[\"txt\", 0]]\n",
        "\n",
        "    # CONVERT THE LABELS\n",
        "    df_orig_modified[0] = df_orig_modified[0]-1\n",
        "\n",
        "    # CHANGE THE COLUMN NAMES SO THAT THEY MATCH\n",
        "    df_orig_modified = df_orig_modified.rename(columns = {0:\"label\"})\n",
        "\n",
        "    # CONCAT THE ADV EXAMPLES AND ORIGINAL SAMPLES\n",
        "    df_concat = pd.concat([df_orig_modified, df_modified]).reset_index(drop=True)\n",
        "\n",
        "    # SAVE THE RESULT\n",
        "    df_concat.to_csv(PATH_DATASET+DIR_TRAIN+\"_ADV.csv\", index=False)\n",
        "\n",
        "elif DIR_TRAIN == \"IMDB\":\n",
        "\n",
        "    # CONVERT POS/NEG TO 1,0\n",
        "    df_orig[\"sentiment\"].replace({\"neg\":0, \"pos\":1}, inplace=True)\n",
        "\n",
        "    # CHANGE THE COLUMN NAMES SO THAT THEY MATCH\n",
        "    df_orig = df_orig.rename(columns={\"text\":\"txt\", \"sentiment\":\"label\"})\n",
        "\n",
        "    # CONCAT THE ADV EXAMPLES AND ORIGINAL SAMPLES\n",
        "    df_concat = pd.concat([df_orig, df_modified]).reset_index(drop=True)\n",
        "\n",
        "    # SAVE THE RESULT\n",
        "    df_concat.to_csv(PATH_DATASET+DIR_TRAIN+\"_ADV.csv\", index=False)\n",
        "\n",
        "elif DIR_TRAIN == \"YahooAnswers\":\n",
        "\n",
        "    # SUBTRACT 1 FROM THE LABELS\n",
        "    df_orig[0] = df_orig[0] - 1\n",
        "\n",
        "    # CONVERT NAN FIELDS TO EMPTY STRING\n",
        "    df_orig.fillna(\"\", inplace=True)\n",
        "\n",
        "    # MAKE ONE FIELD NAMED TXT\n",
        "    df_orig[\"txt\"] = df_orig[1] + \" \" + df_orig[2] + \" \" + df_orig[3]\n",
        "    df_orig_modified = df_orig[[\"txt\", 0]]\n",
        "\n",
        "    # CHANGE THE COLUMN NAMES SO THAT THEY MATCH\n",
        "    df_orig_modified = df_orig_modified.rename(columns = {0:\"label\"})\n",
        "\n",
        "    # CONCAT THE ADV EXAMPLES AND ORIGINAL SAMPLES\n",
        "    df_concat = pd.concat([df_orig_modified, df_modified]).reset_index(drop=True)\n",
        "\n",
        "    # SAVE THE RESULT\n",
        "    df_concat.to_csv(PATH_DATASET+DIR_TRAIN+\"_ADV.csv\", index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MdVF9WUXzsbv",
        "outputId": "0d66d53a-f43e-4720-e4fb-969258644972"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CHECK IF THE TRAIN EXAMPLE FORMED FITS THE TEMPLATE\n",
        "# SCHEMA: \"TXT\", \"LABEL\" WITH ADVERSARIAL EXAMPLES AT THE END\n",
        "\n",
        "df_result = pd.read_csv(PATH_DATASET+DIR_TRAIN+\"_ADV.csv\")\n",
        "df_result"
      ],
      "metadata": {
        "id": "w7O4RpHd319D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "2uLFOLJG5HGu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}